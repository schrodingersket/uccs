%! Author = jonathan %! Date = 11/06/2022

@article{raissi_physics-informed_2019,
  title    = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  volume   = {378},
  issn     = {0021-9991},
  url      = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
  doi      = {https://doi.org/10.1016/j.jcp.2018.10.045},
  abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
  journal  = {Journal of Computational Physics},
  author   = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
  year     = {2019},
  keywords = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods},
  pages    = {686--707},
  file     = {Full Text:/home/jonathan/Zotero/storage/EVGSS52I/Raissi et al. - 2019 - Physics-informed neural networks A deep learning .pdf:application/pdf}
}

@misc{lu_physics-informed_2021,
	title = {Physics-informed neural networks with hard constraints for inverse design},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	url = {https://arxiv.org/abs/2102.04626},
	publisher = {arXiv},
	author = {Lu, Lu and Pestourie, Raphael and Yao, Wenjie and Wang, Zhicheng and Verdugo, Francesc and Johnson, Steven G.},
	year = {2021},
	doi = {10.48550/ARXIV.2102.04626},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), Computational Physics (physics.comp-ph), FOS: Physical sciences},
	file = {Full Text:/home/jonathan/Zotero/storage/2CWQTHKN/Lu et al. - 2021 - Physics-informed neural networks with hard constra.pdf:application/pdf},
}

@article{lu_deepxde_2021,
	title = {{DeepXDE}: {A} deep learning library for solving differential equations},
	volume = {63},
	doi = {10.1137/19M1274067},
	number = {1},
	journal = {SIAM Review},
	author = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
	year = {2021},
	pages = {208--228},
	file = {Full Text:/home/jonathan/Zotero/storage/6EVLUZ4C/Lu et al. - 2021 - DeepXDE A deep learning library for solving diffe.pdf:application/pdf},
}

@article{setiyowati_simulation_2019,
	title = {A {Simulation} of {Shallow} {Water} {Wave} {Equation} {Using} {Finite} {Volume} {Method}: {Lax}-{Friedrichs} {Scheme}},
	volume = {1306},
	url = {https://dx.doi.org/10.1088/1742-6596/1306/1/012022},
	doi = {10.1088/1742-6596/1306/1/012022},
	abstract = {Long wave propagation above a bottom topography such as tsunami waves can be modeled mathematically by applying shallow water wave equations. The finite volume method was developed to determine the numerical solution of shallow water wave equations. The method uses Lax-Friedrichs scheme for the determination of numerical fluxes at cell interfaces. Furthermore, the model and method was applied to the simulation of long wave propagation on a sloping beach. The simulation results shows that the present model and method has a power of simulation of long wave propagation of the tsunami wave on the beach topography with a slope.},
	number = {1},
	journal = {Journal of Physics: Conference Series},
	author = {Setiyowati, R. and {Sumardi}},
	month = aug,
	year = {2019},
	note = {Publisher: IOP Publishing},
	pages = {012022},
	file = {Full Text:/home/jonathan/Zotero/storage/D88F3MRV/Setiyowati and Sumardi - 2019 - A Simulation of Shallow Water Wave Equation Using .pdf:application/pdf},
}

@article{KUTLUAY1999251,
  title    = {Numerical solution of one-dimensional Burgers equation: explicit and exact-explicit finite difference methods},
  journal  = {Journal of Computational and Applied Mathematics},
  volume   = {103},
  number   = {2},
  pages    = {251-261},
  year     = {1999},
  issn     = {0377-0427},
  doi      = {https://doi.org/10.1016/S0377-0427(98)00261-1},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377042798002611},
  author   = {S. Kutluay and A.R. Bahadir and A. Özdeş},
  keywords = {Burgers equation, Exact-explicit finite difference, Explicit finite difference},
  abstract = {This paper presents finite-difference solution and analytical solution of the finite-difference approximations based on the standard explicit method to the one-dimensional Burgers equation which arises frequently in the mathematical modelling used to solve problems in fluid dynamics. Results obtained by these ways for some modest values of viscosity have been compared with the exact (Fourier) one. It is shown that they are in good agreement with each other.}
}

@misc{adam,
  doi = {10.48550/ARXIV.1412.6980},
  url = {https://arxiv.org/abs/1412.6980},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{pino,
  doi = {10.48550/ARXIV.2111.03794},
  url = {https://arxiv.org/abs/2111.03794},
  author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  keywords = {Machine Learning (cs.LG), Numerical Analysis (math.NA), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  title = {Physics-Informed Neural Operator for Learning Partial Differential Equations},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{WU2023115671,
title = {A comprehensive study of non-adaptive and residual-based adaptive sampling for physics-informed neural networks},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {403},
pages = {115671},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115671},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522006260},
author = {Chenxi Wu and Min Zhu and Qinyang Tan and Yadhu Kartha and Lu Lu},
keywords = {Partial differential equations, Physics-informed neural networks, Residual point distribution, Non-adaptive uniform sampling, Uniform sampling with resampling, Residual-based adaptive sampling},
abstract = {Physics-informed neural networks (PINNs) have shown to be effective tools for solving both forward and inverse problems of partial differential equations (PDEs). PINNs embed the PDEs into the loss of the neural network using automatic differentiation, and this PDE loss is evaluated at a set of scattered spatio-temporal points (called residual points). The location and distribution of these residual points are highly important to the performance of PINNs. However, in the existing studies on PINNs, only a few simple residual point sampling methods have mainly been used. Here, we present a comprehensive study of two categories of sampling for PINNs: non-adaptive uniform sampling and adaptive nonuniform sampling. We consider six uniform sampling methods, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence, (5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling strategy for uniform sampling. To improve the sampling efficiency and the accuracy of PINNs, we propose two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D), which dynamically improve the distribution of residual points based on the PDE residuals during training. Hence, we have considered a total of 10 different sampling methods, including six non-adaptive uniform sampling, uniform sampling with resampling, two proposed adaptive sampling, and an existing adaptive sampling. We extensively tested the performance of these sampling methods for four forward problems and two inverse problems in many setups. Our numerical results presented in this study are summarized from more than 6000 simulations of PINNs. We show that the proposed adaptive sampling methods of RAD and RAR-D significantly improve the accuracy of PINNs with fewer residual points for both forward and inverse problems. The results obtained in this study can also be used as a practical guideline in choosing sampling methods.}
}