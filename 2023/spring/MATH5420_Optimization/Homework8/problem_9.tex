\textbf{Griva, Nash, Sofer 14.5.7}

Use the optimality conditions to find all local solutions to the problem

\begin{mini*}
    {}{f(x) = x_1 + x_2}{}{}
    \addConstraint{(x_1 - 1)^2 + x_2^2}{\le 2}
    \addConstraint{(x_1 + 1)^2 + x_2^2}{\ge 2}.
\end{mini*}

\begin{solution}
    For convenience, we enumerate our constraints as follows:

    $$
    g_1(x) = 2 - (x_1 - 1)^2 - x_2^2 \ge 0, \quad g_2(x) = (x_1 + 1)^2 + x_2^2 - 2 \ge 0.
    $$

    so that the gradients of our constraints are

    $$
    \nabla g_1 = \begin{pmatrix*}
        2 - 2 x_1 \\
        -2 x_2
    \end{pmatrix*}, \quad \nabla g_2 = \begin{pmatrix*}
        2 + 2 x_1 \\
        2 x_2
    \end{pmatrix*}
    $$

    Since we have two constraints, we have two Lagrange multipliers and our Lagrangian is therefore

    $$
    \mathcal{L}(x, \lambda) = f(x) - \lambda_1 g_1 - \lambda_2 g_2 
                            = x_1 + x_2 - \lambda_1 \left[ 2 - (x_1 - 1)^2 - x_2^2 \right] - \lambda_2 \left[ (x_1 + 1)^2 + x_2^2 - 2 \right]
    $$

    where the gradient of the Lagrangian with respect to $x$ is 

    $$
    \nabla_x \mathcal{L} = \nabla f(x) - \lambda_1 \nabla g_1 - \lambda_2 \nabla g_2 = \begin{pmatrix*}
        1 \\
        1
    \end{pmatrix*} - \lambda_1 \begin{pmatrix*}
        2 - 2 x_1 \\
        -2 x_2
    \end{pmatrix*} - \lambda_2 \begin{pmatrix*}
        2 + 2 x_1 \\
        2 x_2
    \end{pmatrix*}
    $$

    with corresponding Hessian

    $$
    \nabla^2_{xx} \mathcal{L} = \begin{pmatrix*}
        2 \lambda_1 - 2 \lambda_2 & 0 \\
                                0 & 2 \lambda_1 - 2 \lambda_2
    \end{pmatrix*}
    $$
    
    so that feasible stationary points are minimizers whenever $\lambda_1 > \lambda_2$ and maximizers whenever 
    $\lambda_1 < \lambda_2$. We now proceed to compute stationary points by enforcing our first-order necessary 
    condition that $\nabla_x \mathcal{L} = 0$ along with strict complementarity by cases.

    \paragraph{Case I:} $\lambda_1 = \lambda_2 = 0.$ \ \\
    When all Lagrange multipliers are zero, our first-order necessary condition becomes

    $$
    \begin{pmatrix*}
        0 \\
        0
    \end{pmatrix*} = \nabla_x \mathcal{L} = \begin{pmatrix*}
        1 \\
        1
    \end{pmatrix*}
    $$

    which admits no stationary points.

    \paragraph{Case II:} $g_1 = g_2 = 0.$ \ \\
    When both constraints are active, we obtain the system of equations

    $$
    \begin{pmatrix*}[r]
        -(x_1 - 1)^2 - x_2^2 + 2 \\
         (x_1 + 1)^2 + x_2^2 - 2
    \end{pmatrix*} = \begin{pmatrix*}
        0 \\
        0
    \end{pmatrix*}
    $$

    Adding the equations together yields $x_1 = 0$, from which we obtain $x_2 = \pm 1$ upon substituting $x_1$ into 
    either equation. We therefore have two stationary points $(0, -1)^T$ and $(0, 1)^T$. When $x_* = (0, -1)^T$, our 
    first-order necessary condition yields

    $$
    \begin{pmatrix*}
        1 - 2 \lambda_1 - 2 \lambda_2 \\
        1 - 2 \lambda_1 + 2 \lambda_2
    \end{pmatrix*} = \begin{pmatrix*}
        0 \\
        0
    \end{pmatrix*}
    $$

    and hence $\lambda_1 = \frac{1}{2}$ and $\lambda_2 = 0$. Since $\lambda_1 > \lambda_2$, the point $x_* = (0, -1)$ is
    a local minimizer. Conversely, when $x_* = (0, 1)^T$, our first-order necessary condition yields

    $$
    \begin{pmatrix*}
        1 - 2 \lambda_1 - 2 \lambda_2 \\
        1 + 2 \lambda_1 - 2 \lambda_2
    \end{pmatrix*} = \begin{pmatrix*}
        0 \\
        0
    \end{pmatrix*}
    $$

    from which we obtain $\lambda_1 = 0$ and $\lambda_2 = \frac{1}{2}$. Since $\lambda_1 < \lambda_2$, the point 
    $x_* = (0, 1)$ is a local maximizer.
    
    \paragraph{Case III:} $\lambda_1 = g_2 = 0.$ \ \\
    When $\lambda_1 = 0$, our first-order necessary condition yields

    $$
    \nabla_x \mathcal{L} = \nabla f(x) - \lambda_2 \nabla g_2 = \begin{pmatrix*}
        1 \\
        1
    \end{pmatrix*} - \lambda_2 \begin{pmatrix*}
        2 + 2 x_1 \\
        2 x_2
    \end{pmatrix*} = \begin{pmatrix*}
        0 \\
        0
    \end{pmatrix*}
    $$

    which yields $x_1 = \frac{1}{2 \lambda_2} - 1$ and $x_2 = \frac{1}{2 \lambda_2}$. After substituting these values 
    into the active constraint $g_2 = 0$, we find

    $$
    \left( \frac{1}{2 \lambda_2} \right)^2 = 1
    $$

    so that $\lambda_2 = \pm \frac{1}{2}$. Our necessary conditions for a minimizer require $\lambda \ge 0$, and so we 
    let $\lambda_2 = \frac{1}{2}$ to obtain the feasible point $x_* = (0, 1)^T$, which we have already determined to be 
    a local maximizer in \textbf{Case II}.

    \paragraph{Case IV:} $\lambda_2 = g_1 = 0.$ \ \\
    When $\lambda_2 = 0$, our first-order necessary condition yields

    $$
    \nabla_x \mathcal{L} = \nabla f(x) - \lambda_1 \nabla g_1 = \begin{pmatrix*}
        1 \\
        1
    \end{pmatrix*} - \lambda_1 \begin{pmatrix*}
        2 - 2 x_1 \\
        -2 x_2
    \end{pmatrix*}
    $$

    which yields $x_1 = -\frac{1}{2 \lambda_1} + 1$ and $x_2 = -\frac{1}{2 \lambda_1}$. After substituting these values 
    into the active constraint $g_1 = 0$, we find

    $$
    \left( -\frac{1}{2 \lambda_1} \right)^2 = 1
    $$

    so that $\lambda_1 = \pm \frac{1}{2}$. We exclude $\lambda_1 = -\frac{1}{2}$ since we require $\lambda \ge 0$; 
    letting $\lambda_1 = \frac{1}{2}$ yields the feasible point $x_* = (0, -1)^T$, which we have already determined to 
    be a local minimizer in \textbf{Case II}.
    \ \\\\
    Our only local minimizer is therefore $x_* = (0, -1)$, which yields the optimal value

    $$
    f(x) = x_1 + x_2 = 0 - 1 = -1.
    $$
    \ \\
\end{solution}